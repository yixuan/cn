---
date: '2012-03-05 23:11:00'
layout: post
slug: something-about-clt
status: publish
title: CLT的一些事
categories:
- 学习中
tags:
- 分布
- 中心极限定理
- 变异
- 均值
- 大师
- 大样本
- 对称
- 样本量
- 正态分布
---

最近在读 E. L. Lehmann 的 *Elements of Large-Sample Theory* 一书。说起大样本和渐进理论，我一向是敬而远之，因为只要一碰到测度论和极限定理，我就不由自主地发怵。但这本书着实给了我很多惊喜，因为整本书几乎没有提到测度这两个字，简单翻阅了一下，感觉以数学分析的内容就可以看懂其中的大部分证明，于是甚感欣慰。大师的作品确实有其独到之处，读起来很少有晦涩难懂的地方，于是趁着现在时间相对宽松，也想在大样本理论这一块入个门。Lehmann也是一位令人尊敬的大师级人物，写过不少点估计和假设检验方面的经典教材，遗憾的是于2009年与世长辞。

今天看了跟中心极限定理有关的一些内容，从中了解到了不少之前没有考虑过的问题，而书中也解答了一些我一直留存的疑问，所以一并记录在这里。

<!-- more -->

### 平均后的变异程度

中心极限定理考察的对象是一列随机变量样本均值的分布。定理的表述有很多种，在这里只考虑最简单的情形：样本独立同分布。我们直觉会认为，样本均值会比原始的随机变量更稳定、更集中，最后成为一个方差逐渐趋于0的正态分布。经过一定的标准化处理，极限分布就是标准正态分布。但事实上，对变量进行平均，并不一定能减小分布的变异程度。例如，对于柯西分布来说，将两个独立的柯西分布进行平均，其结果仍然是一个同分布的柯西分布，所以相应地，均值的极限分布与单个的变量分布相同。

此外还有“越平均越变异”的分布。书中举的例子是标准正态分布的平方倒数，即$$X=1/Y^2$$，其中$$Y \sim N(0,1)$$。对于这个分布来说，$$\bar{X}$$与$$nX_1$$是同分布的，所以样本量越大，均值的分布越分散。

下面的三组箱线图是对这三种分布的一个对比，横轴是样本量，纵轴是均值分布的箱线图。可以看出，对于正态分布，样本量越大，均值抽样分布的离散程度越小；对于柯西分布，离散程度几乎不变；对于第三种分布，很明显离散程度迅速变大。需要注意的是，绘制箱线图的数据只取了中间的一半，因此实际的分布会比箱线图所反映出的更加分散。

[![正态分布均值分布](https://i.imgur.com/KO8rPur.png)](https://i.imgur.com/KO8rPur.png)
[![柯西分布均值分布](https://i.imgur.com/1wzCKN9.png)](https://i.imgur.com/1wzCKN9.png)
[![正态分布平方倒数的均值分布](https://i.imgur.com/onm403J.png)](https://i.imgur.com/onm403J.png)


### 样本量要多大才正态？

如果我们记$$\sqrt{n}(\bar{X}-\xi)/\sigma$$的分布函数是$$G_n(x)$$，那么中心极限定理说的其实就是当$$n\rightarrow \infty$$时，对任意的$$x$$有$$G_n(x)\rightarrow \Phi(x)$$。于是这里就出现了一个问题：到底n要多大$$G_n(x)$$才与标准正态比较接近？

我一直以为这个问题是无解的，因为我感觉没有一个普世的准则对所有的分布都有效。直到今天才看到书中引用了一个定理，对这个问题进行了解答。定理是这样说的：

Berry-Esseen定理：假设$$X_1,\ldots, X_n$$独立同分布（分布函数为F），且具有有限的三阶矩，那么存在一个与F无关的常数C，使得对任意的x，都有

$$\vert G_n(x)-\Phi(x)\rvert\le \frac{C}{\sqrt{n}}\frac{E\lvert X_1-\xi\rvert^3}{\sigma^3}$$

目前已知该定理对C=0.7975成立，对C<0.4097不成立，但C可能的最小值依然是未知的。这个定理最强大的地方在于它对任意的x和任意的n都是成立的，所以不管x是否在变动，以及不管n有多大，你都可以给出当前均值分布与正态分布的绝对误差！从另一个方面说，只要你指定一个允许的误差，你就能计算出满足这个误差上界所需的样本量大小。

### 因为对称，所以正态？

益辉在[这篇文章](http://cos.name/2010/05/from-clt-simulation-to-normal-distribution/)中指出了一个问题，那就是很多教科书在对中心极限定理举例时都喜欢拿对称的分布来做，而一旦原始分布不对称，往往要当样本量很大时均值分布才接近正态。当时我就想，是什么原因使得对称分布有这样的优越性？同样是直到今天，我才在书中找到了对这个疑惑的一个合理的解释。

注意到之前的Berry-Esseen定理中，等号右边是$$1/\sqrt{n}$$，但既然是小于等于号，我们就不禁要问，收敛的速度有没有可能更快？要回答这个问题，我们就需要用到下面的这个定理：

假设$$X_1,\ldots, X_n$$独立同分布（分布函数为F），具有有限的三阶矩，且不是一个格点分布，那么

$$G_n(x)=\Phi(x)+\frac{\mu_3}{6\sigma^3 \sqrt{n}}(1-x^2)\phi(x)+o(\frac{1}{\sqrt{n}})$$

其中$$\mu_k=E(X-\xi)^k$$表示k阶中心矩，上式中的第二项称为一阶Edgeworth正态近似修正。

这个定理的意思是，$$G_n(x)$$趋近于$$\Phi(x)$$的速度由两部分决定，一部分是$$1/\sqrt{n}$$的速度，另一部分是比$$1/\sqrt{n}$$更快的速度。而如果第一部分等于0，那么趋近的速度就可以更快。要达到这个目的，唯一的可能是让$$\mu_3$$等于0，而这恰恰意味着分布的偏度等于0，也就是说是对称的分布。至此，真相大白。

